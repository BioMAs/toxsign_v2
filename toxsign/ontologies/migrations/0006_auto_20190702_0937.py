# Generated by Django 2.0.13 on 2019-07-02 09:37

from django.db import migrations
from django_elasticsearch_dsl.registries import registry
import toxsign.ontologies.models as onto_models

import csv
import pronto
import os
import requests
import time

ontology_models = {
    'biological': 'Biological',
    'cellline': 'CellLine',
    'cell': 'Cell',
    'chemical': 'Chemical',
    'disease': 'Disease',
    'experiment': 'Experiment',
    'specie': 'Species',
    'tissue': 'Tissue'
}

def process_ontology(ontology, model, parent_id="", ancestor_id_list=[], start=False, processed = []):

    if not ontology.id:
        return processed
    # Only process first rank ontology (to avoid starting the tree in the middle)
    if start and ontology.parents:
        # In case one parent is children or whatever
        # Might be a better way for Thing..
        if not all([parent in ontology.children for parent in ontology.parents]) and not all([parent.id == "Thing" for parent in ontology.parents]):
            return processed

    if ontology.id in processed:
        # If multiple parents, we only parsed one branch, but the object still exist
        # Add new parent and new ancestors
        if len(ontology.parents) > 1:
            object = model.objects.get(onto_id=ontology.id)
            if parent_id:
                object.as_parent.set(parent_id)
            if ancestor_id_list:
                object.as_ancestor.set(ancestor_id_list)
        return processed

    id = ontology.id
    name = ontology.name if ontology.name else ontology.id

    if ontology.synonyms:
        synonyms = ",".join([synonym.desc for synonym in ontology.synonyms])

    object = model.objects.create(onto_id=id, name=name, synonyms=synonyms)
    if parent_id:
        object.as_parent.set(parent_id)
    if ancestor_id_list:
        object.as_ancestor.set(ancestor_id_list)

    # Add parents & ancestors id here
    # Recursive loop to scale down the tree
    ancestor_id_list.append(object.id)
    processed.append(ontology.id)

    for child in ontology.children:
        processed = process_ontology(child, model, object.id, ancestor_id_list, processed=processed)
    return processed

def download_ontology(onto, lock):
    url = onto['url']
    path = onto['path']
    model = onto['model']

    if not os.path.exists(path):
        r = requests.get(url, stream=True)
        if r.status_code == 200:
            with open(path, 'wb') as f:
                for chunk in r:
                    f.write(chunk)
    lock.acquire()
    if not os.path.exists(path):
        print("Error : file not found " + path)
        print("Skipping")
        lock.release()
    try:
        print("Processing onto " + path)
        processed = []
        start = time.time()
        ontologies = pronto.Ontology(path)
        for ontology in ontologies:
            processed = process_ontology(ontology, model, start=True, processed=processed)
        end = time.time()
        print("Time:")
        print(end - start)
        print(len(ontologies) - len(processed))
    except Exception as e:
        print(e)
    finally:
        lock.release()

def launch_import(apps, schema_editor):
    start = time.time()
    lock = Lock()
    url_list = []
    with open('TOXsIgN_ontologies.csv', 'r') as line:
        next(line)
        tsv = csv.reader(line)
        for row in tsv:
            if row[3] == 'owl' or row[3] == 'obo':
                model = apps.get_model('ontologies', ontology_models[row[2]])
                url_list.append({"url": row[1], "path": row[4]}, "model": model)
    procs = []
    for onto in url_list:
        p = Process(target=download_ontology, args=(onto, lock))
        p.start()
        procs.append(p)

    for proc in procs:
        proc.join()
    stop = time.time()
    print(stop-start)

class Migration(migrations.Migration):

    dependencies = [
        ('ontologies', '0005_auto_20190529_1039'),
        ('signatures', '0004_auto_20190723_0815_squashed_0005_auto_20190801_0815'),
        ('assays', '0006_remove_assay_status'),
        ('projects', '0007_auto_20190905_1324'),
    ]

    operations = [
	migrations.RunPython(launch_import),
    ]
